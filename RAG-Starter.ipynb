{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lDHQRQCY24w7"
   },
   "source": [
    "# **1. Install Dependencies**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3qA3VNJUskF6",
    "outputId": "cfb6a1ce-5b59-4830-e774-1a0d568946ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pinecone in c:\\users\\pc\\anaconda3\\lib\\site-packages (7.3.0)\n",
      "Requirement already satisfied: langchain-community in c:\\users\\pc\\anaconda3\\lib\\site-packages (0.4.1)\n",
      "Requirement already satisfied: streamlit in c:\\users\\pc\\anaconda3\\lib\\site-packages (1.37.1)\n",
      "Requirement already satisfied: ollama in c:\\users\\pc\\anaconda3\\lib\\site-packages (0.6.1)\n",
      "Requirement already satisfied: langchain-ollama in c:\\users\\pc\\anaconda3\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: langchain_pinecone in c:\\users\\pc\\anaconda3\\lib\\site-packages (0.2.13)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from pinecone) (2024.12.14)\n",
      "Requirement already satisfied: pinecone-plugin-assistant<2.0.0,>=1.6.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from pinecone) (1.8.0)\n",
      "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from pinecone) (0.0.7)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from pinecone) (2.9.0.post0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from pinecone) (4.15.0)\n",
      "Requirement already satisfied: urllib3>=1.26.5 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from pinecone) (2.2.3)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.1 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from langchain-community) (1.2.7)\n",
      "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from langchain-community) (1.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from langchain-community) (2.0.34)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.5 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from langchain-community) (2.32.5)\n",
      "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from langchain-community) (6.0.1)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from langchain-community) (3.10.5)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from langchain-community) (8.2.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from langchain-community) (2.12.0)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from langchain-community) (0.6.6)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from langchain-community) (0.4.3)\n",
      "Requirement already satisfied: numpy>=1.26.2 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: altair<6,>=4.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from streamlit) (5.0.1)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from streamlit) (1.6.2)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from streamlit) (5.3.3)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from streamlit) (8.1.7)\n",
      "Requirement already satisfied: packaging<25,>=20 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from streamlit) (24.2)\n",
      "Requirement already satisfied: pandas<3,>=1.3.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from streamlit) (2.2.2)\n",
      "Requirement already satisfied: pillow<11,>=7.1.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from streamlit) (10.4.0)\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from streamlit) (4.25.3)\n",
      "Requirement already satisfied: pyarrow>=7.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from streamlit) (16.1.0)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from streamlit) (13.7.1)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from streamlit) (3.1.43)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from streamlit) (0.8.0)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from streamlit) (6.4.1)\n",
      "Requirement already satisfied: watchdog<5,>=2.1.5 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from streamlit) (4.0.1)\n",
      "Requirement already satisfied: httpx>=0.27 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from ollama) (0.28.1)\n",
      "Requirement already satisfied: pydantic>=2.9 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from ollama) (2.12.5)\n",
      "Requirement already satisfied: langchain-openai>=0.3.11 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from langchain_pinecone) (1.1.7)\n",
      "Requirement already satisfied: simsimd>=5.9.11 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from langchain_pinecone) (6.5.12)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.11.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
      "Requirement already satisfied: toolz in c:\\users\\pc\\anaconda3\\lib\\site-packages (from altair<6,>=4.0->streamlit) (0.12.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\pc\\anaconda3\\lib\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.7)\n",
      "Requirement already satisfied: anyio in c:\\users\\pc\\anaconda3\\lib\\site-packages (from httpx>=0.27->ollama) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\pc\\anaconda3\\lib\\site-packages (from httpx>=0.27->ollama) (1.0.2)\n",
      "Requirement already satisfied: idna in c:\\users\\pc\\anaconda3\\lib\\site-packages (from httpx>=0.27->ollama) (3.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.27->ollama) (0.14.0)\n",
      "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.1.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.1->langchain-community) (1.33)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.1->langchain-community) (0.14.0)\n",
      "Requirement already satisfied: openai<3.0.0,>=1.109.1 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from langchain-openai>=0.3.11->langchain_pinecone) (2.16.0)\n",
      "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from langchain-openai>=0.3.11->langchain_pinecone) (0.12.0)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (3.11.5)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.23.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from pandas<3,>=1.3.0->streamlit) (2023.3)\n",
      "Requirement already satisfied: aiohttp-retry<3.0.0,>=2.9.1 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from pinecone[asyncio]<8.0.0,>=6.0.0->langchain_pinecone) (2.9.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from pydantic>=2.9->ollama) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from pydantic>=2.9->ollama) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from pydantic>=2.9->ollama) (0.4.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (0.21.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from python-dateutil>=2.5.3->pinecone) (1.16.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.3.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from rich<14,>=10.14.0->streamlit) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from rich<14,>=10.14.0->streamlit) (2.15.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.0.1)\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.1->langchain-community) (2.1)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.10.6)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai>=0.3.11->langchain_pinecone) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai>=0.3.11->langchain_pinecone) (0.12.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\pc\\anaconda3\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai>=0.3.11->langchain_pinecone) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai>=0.3.11->langchain_pinecone) (4.66.5)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai>=0.3.11->langchain_pinecone) (2024.9.11)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pinecone langchain-community streamlit ollama langchain-ollama langchain_pinecone langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama import Client\n",
    "\n",
    "client = Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6wyoZSPp3Fss"
   },
   "source": [
    "# **2. Instantiate an instance of the Pinecone client.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "w5_NIXLK1UbN"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pinecone import Pinecone\n",
    "\n",
    "\n",
    "\n",
    "# Get your API key at app.pinecone.io\n",
    "api_key = os.environ.get(\"PINECONE_API_KEY\") or \"pcsk_476Mbq_K7Z3aCy8BqmFGYrsbHHwhoeRLcfz9yWg8qbpmZMFBEnCMZR6PsPqPiuzDs9neEe\"\n",
    "\n",
    "# Instantiate the Pinecone client\n",
    "pc = Pinecone(api_key=api_key)\n",
    "\n",
    "# Giving our index a name\n",
    "index_name = \"chatbot-index\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2LIfhoo5Kycf",
    "outputId": "babf744e-90dd-42ad-8fa2-eabd2fa01275"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pinecone index initialized!\n"
     ]
    }
   ],
   "source": [
    "from pinecone import ServerlessSpec, CloudProvider, AwsRegion, Metric\n",
    "\n",
    "# Create an index if it doesn't exist\n",
    "if index_name not in pc.list_indexes().names():\n",
    "   pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=1024,  # Use 1536 for `text-embedding-3-large`\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
    "    )\n",
    "index = pc.Index(index_name)\n",
    "print(\"Pinecone index initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the index\n",
    "# pc .delete_index(\"chatbot-index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4zxKB2GXSPcX"
   },
   "source": [
    "# **3. Loading Data from PDFs and CSVs Or Websites**\n",
    "\n",
    "* WebBaseLoader to load all text from HTML webpages into a document format that we can use downstream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set user agent variable to identify requests\n",
    "import os\n",
    "\n",
    "os.environ[\"USER_AGENT\"] = \"MyLangChainBot/1.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h-8odUCIQSIA",
    "outputId": "c52f0564-c9f0-4ac6-9957-0e019fb4e28f"
   },
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader, CSVLoader, PyPDFLoader\n",
    "\n",
    "# load data from website\n",
    "def WebsiteLoader(urls):\n",
    "    loader = WebBaseLoader(urls)\n",
    "    return loader.load()\n",
    "\n",
    "urls = [\"https://nextjs.org/\",\"https://vuejs.org/\"]\n",
    "website_docs = WebsiteLoader(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "-CDCc5-DcNGP",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef load_csvs(file_paths):\\n    docs = []\\n    for file_path in file_paths:\\n        docs.extend(CSVLoader(file_path=file_path).load())\\n    return docs\\n\\n\\ncsv_docs = load_csvs([\"\"])\\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data from csv files\n",
    "\n",
    "\"\"\"\n",
    "def load_csvs(file_paths):\n",
    "    docs = []\n",
    "    for file_path in file_paths:\n",
    "        docs.extend(CSVLoader(file_path=file_path).load())\n",
    "    return docs\n",
    "\n",
    "\n",
    "csv_docs = load_csvs([\"\"])\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eXJGZgM3b5w5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load data from pdf files\n",
    "\n",
    "\"\"\"\n",
    "def load_pdfs(pdf_files):\n",
    "    docs = []\n",
    "    for pdf_file in pdf_files:\n",
    "        docs.extend(PyPDFLoader(file_path=pdf_file).load())\n",
    "\n",
    "pdf_docs = load_pdfs([\"\"])\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-KM2uPtRaLvp",
    "outputId": "1e079a5f-a8fc-44d5-f924-b55a6e8602e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://nextjs.org/', 'title': 'Next.js by Vercel - The React Framework', 'description': 'Next.js by Vercel is the full-stack React framework for the web.', 'language': 'en'}, page_content=\"Next.js by Vercel - The React FrameworkSkip to contentSearch documentation...Search...âŒ˜KShowcaseDocsBlogTemplatesEnterpriseSearch documentation...Search...âŒ˜KDeployLearnThe React Framework for the WebUsed by some of the world's largest companies, Next.js enables you to create high-quality web applications with the power of React components.Get StartedLearn Next.jsâ–² ~ npx create-next-app@latestWhat's in Next.js?Everything you need to build great products on the web.Data FetchingMake your React component async and await your data. Next.js supports both server and client data fetching.Server ActionsRun server code by calling a function. Skip the API. Then, easily revalidate cached data and update your UI in one network roundtrip.Advanced Routing & Nested LayoutsCreate routes using the file system, including support for more advanced routing patterns and UI layouts.CSS SupportStyle your application with your favorite tools, including support for CSS Modules, Tailwind CSS, and popular community libraries.Route HandlersBuild API endpoints to securely connect with third-party services for handling auth or listening for webhooks.MiddlewareTake control of the incoming request. Use code to define routing and access rules for authentication, experimentation, and internationalization.React Server ComponentsAdd components without sending additional client-side JavaScript. Built on the latest React features.Client and Server RenderingFlexible rendering and caching options, including Incremental Static Regeneration (ISR), on a per-page level.React Server ComponentsAdd components without sending additional client-side JavaScript. Built on the latest React features.Data FetchingMake your React component async and await your data. Next.js supports both server and client data fetching.Server ActionsRun server code by calling a function. Skip the API. Then, easily revalidate cached data and update your UI in one network roundtrip.Advanced Routing & Nested LayoutsCreate routes using the file system, including support for more advanced routing patterns and UI layouts.CSS SupportStyle your application with your favorite tools, including support for CSS Modules, Tailwind CSS, and popular community libraries.Route HandlersBuild API endpoints to securely connect with third-party services for handling auth or listening for webhooks.MiddlewareTake control of the incoming request. Use code to define routing and access rules for authentication, experimentation, and internationalization.Client and Server RenderingFlexible rendering and caching options, including Incremental Static Regeneration (ISR), on a per-page level.React Server ComponentsAdd components without sending additional client-side JavaScript. Built on the latest React features.Data FetchingMake your React component async and await your data. Next.js supports both server and client data fetching.Server ActionsRun server code by calling a function. Skip the API. Then, easily revalidate cached data and update your UI in one network roundtrip.Advanced Routing & Nested LayoutsCreate routes using the file system, including support for more advanced routing patterns and UI layouts.CSS SupportStyle your application with your favorite tools, including support for CSS Modules, Tailwind CSS, and popular community libraries.Route HandlersBuild API endpoints to securely connect with third-party services for handling auth or listening for webhooks.MiddlewareTake control of the incoming request. Use code to define routing and access rules for authentication, experimentation, and internationalization.Client and Server RenderingFlexible rendering and caching options, including Incremental Static Regeneration (ISR), on a per-page level.Next.js 16The power of full-stack to the frontend. Read the release notes.Built on a foundation of fast,  production-grade toolingPowered ByReactThe library for web and native user interfaces. Next.js is built on the latest React features, including Server Components and Actions.TurbopackAn incremental bundler optimized for JavaScript and TypeScript, written in Rust , and built into Next.js.Speedy Web CompilerAn extensible Rust  based platform for the next generation of fast developer tools, and can be used for both compilation and minification.Get started in secondsDeploy Next.js to VercelStarterEcommerceBlogAIPortfolioSaaSMulti-tenant AppsRealtime AppsDocumentationVirtual EventWeb3Vercel is a frontend cloud from the creators of Next.js, making it easy to get started with Next.js quickly.Jumpstart your Next.js development with pre-built solutions from Vercel and our community.Deploy a Template on VercelNext.js BoilerplateA Next.js starter from create-next-app.Image Gallery StarterAn image gallery built on Next.js and Cloudinary.Next.js CommerceAn all-in-one starter kit for high-performance ecommerce sites.The framework of choice  when it mattersAudibleSonosDiceNotionTodayProductHuntNikeWashington PostSonosAudibleNikeNotionProductHuntWashington PostFor performance, efficiency and developer experience. Next.js is trusted by some of the biggest names on the web.View the Next.js ShowcaseCustomer Testimonialsâ€œWith Next.js, we now consistently average 0.09 or lower for Cumulative Layout Shift, placing our site in the top tier for user experience and Core Web Vitals.â€Senior Software Engineer, Frontendâ€œOur UI for Frame.io responds to user input within 100ms and all animations run at a consistent 60fps with Next.js.â€Charlton Roberts, Product Engineeringâ€œNext.js has been a game-changer for our agency work and team collaboration. Its powerful features have allowed us to build high-performance websites quickly and efficiently like never before.â€Daniel Lopes, Frontend DeveloperResourcesDocsSupport PolicyLearnShowcaseBlogTeamAnalyticsNext.js ConfPreviewsEvalsMoreNext.js CommerceContact SalesCommunityGitHubReleasesTelemetryGovernanceAbout VercelNext.js + VercelOpen Source SoftwareGitHubBlueskyXLegalPrivacy PolicyCookie PreferencesSubscribe to our newsletterStay updated on new releases and features, guides, and case studies.SubscribeÂ© 2026 Vercel, Inc.Original1440px375pxBuilt-in OptimizationsAutomatic Image, Font, and Script Optimizations for improved UX and Core Web Vitals.Dynamic HTML StreamingInstantly stream UI from the server, integrated with the App Router and React Suspense.Next.js 16The power of full-stack to the frontend. Read the release notes.Built-in OptimizationsAutomatic Image, Font, and Script Optimizations for improved UX and Core Web Vitals.Dynamic HTML StreamingInstantly stream UI from the server, integrated with the App Router and React Suspense.Next.js 16The power of full-stack to the frontend. Read the release notes.Built-in OptimizationsAutomatic Image, Font, and Script Optimizations for improved UX and Core Web Vitals.Dynamic HTML StreamingInstantly stream UI from the server, integrated with the App Router and React Suspense.\"),\n",
       " Document(metadata={'source': 'https://vuejs.org/', 'title': 'Vue.js - The Progressive JavaScript Framework | Vue.js', 'description': 'Vue.js - The Progressive JavaScript Framework', 'language': 'en-US'}, page_content='\\n\\n\\n\\n\\nVue.js - The Progressive JavaScript Framework | Vue.js\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSkip to contentVue.jsSearchMain NavigationDocs GuideTutorialExamplesQuick StartGlossaryError ReferenceVue 2 DocsMigration from Vue 2APIPlaygroundEcosystem ResourcesPartnersThemesUI ComponentsPlugins CollectionCertificationJobsT-Shirt ShopOfficial LibrariesVue RouterPiniaTooling GuideVideo CoursesVue MasteryVue SchoolHelpDiscord ChatGitHub DiscussionsDEV CommunityNewsBlogTwitterEventsNewslettersAbout FAQTeamReleasesCommunity GuideCode of ConductPrivacy PolicyThe DocumentarySponsorPartnersç®€ä½“ä¸­æ–‡ æ—¥æœ¬èªž Ð£ÐºÑ€Ð°Ñ—Ð½ÑÑŒÐºÐ° FranÃ§ais í•œêµ­ì–´ PortuguÃªs à¦¬à¦¾à¦‚à¦²à¦¾ Italiano ÙØ§Ø±Ø³ÛŒ Ð ÑƒÑÑÐºÐ¸Ð¹ ÄŒeÅ¡tina ç¹é«”ä¸­æ–‡ Polski Help Us Translate!githubtwitterdiscordAppearancegithubtwitterdiscord The ProgressiveJavaScript Framework  An approachable, performant and versatile framework for building web user interfaces. Play icon Why Vue  Get Started Install Get Security Updates for Vue 2  Special Sponsor slot is now vacant - Inquire now Approachable Builds on top of standard HTML, CSS and JavaScript with intuitive API and world-class documentation. Performant Truly reactive, compiler-optimized rendering system that rarely requires manual optimization. Versatile A rich, incrementally adoptable ecosystem that scales between a library and a full-featured framework. Platinum SponsorsBecome a SponsorGold SponsorsBecome a SponsorDocsGuideTutorialExamplesQuick StartGlossaryError ReferenceVue 2 DocsMigration from Vue 2AboutFAQTeamReleasesCommunity GuideCode of ConductPrivacy PolicyThe DocumentaryResourcesPartnersThemesUI ComponentsPlugins CollectionCertificationJobsT-Shirt ShopOfficial LibrariesVue RouterPiniaTooling GuideVideo CoursesVue MasteryVue SchoolHelpDiscord ChatGitHub DiscussionsDEV CommunityNewsBlogTwitterEventsNewslettersReleased under the MIT License.Copyright Â© 2014-2026 Evan YouVue.js - The Progressive JavaScript Framework has loaded\\n\\n\\n')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "website_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sQwLaP-6Z7jy"
   },
   "source": [
    "4. Chunking: breaking the data into small chunks\n",
    "\n",
    "  * RecursiveCharacterTextSplitter is a text-splitting tool that breaks documents into smaller parts while maintaining logical relationships.\n",
    "  * chunk_size=500 â†’ Each chunk will have a maximum of 500 characters.\n",
    "  * chunk_overlap=100 â†’ Chunks will have 100-character overlap to maintain context.\n",
    "  * length_function=len â†’ Uses character length to determine chunk size.\n",
    "  * is_separator_regex=False â†’ The separator used for splitting is not a regex pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "j0LeP9-OSulG"
   },
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,chunk_overlap=100, length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "\n",
    "# all_documents = website_docs + csv_docs + pdf_docs -> merges text data from websites, CSV files, and PDFs into a single list for processing.\n",
    "all_documents = website_docs\n",
    "\n",
    "splited_documents = text_splitter.split_documents(all_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q6Gsfe4-ahUa",
    "outputId": "9dbb80a9-cf70-4247-e26d-b49860127383"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(splited_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jBaH2nrjcxCQ"
   },
   "source": [
    "# **5. Embedding Documents and Storing in Pinecone**\n",
    "\n",
    "\n",
    "\n",
    "*  import OllamaEmbeddings, a model for converting text into vector representations (numerical embeddings).\n",
    "* Uses Ollamaâ€™s mxbai-embed-large model to generate vector embeddings for text.\n",
    "These embeddings represent textual content in a high-dimensional space, enabling similarity search.\n",
    "* PineconeVectorStore is a vector database that efficiently stores and retrieves vectorized documents.\n",
    "* embedding=embeddings â†’ Uses Ollama embeddings to convert text into vectors before storage.\n",
    "* index=index â†’ Specifies the Pinecone index where vectors will be stored.\n",
    "* Converts splited_documents into vectors using OllamaEmbeddings.\n",
    "* Stores the vectorized documents in Pinecone for fast semantic search and retrieval.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 321
    },
    "id": "YLUcaUZeak5h",
    "outputId": "1ab93626-e4c1-427b-9299-c3769ca808c3",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['493634df-b809-4986-acd7-f12df66de9f0',\n",
       " 'a1137871-b1fa-40a9-a169-b4acaca77f41',\n",
       " '57a1186b-cafe-48da-8723-10e80fb2d639',\n",
       " '70c91262-d4a8-492a-b2b0-12cfa9426b4e',\n",
       " 'ab0851b4-6f63-49c1-8324-8d65be649d84',\n",
       " 'd7c4f99b-ffd4-4070-aee7-d9be71b51150',\n",
       " 'f65eeb80-4220-4671-a8d7-16b962491ee3',\n",
       " '0a3f6d5c-99a1-4be2-8e0f-a526479643c7',\n",
       " '583008f9-c23d-4424-b824-50fa9f54728e',\n",
       " '04bc21de-a24f-44d7-baa1-cd5612da0267',\n",
       " 'd1b680fb-f529-49ed-9330-ad4833884969',\n",
       " 'f5d2e82e-b9a1-4431-bb65-fe4c2a3ad902',\n",
       " '59995c3d-9155-4964-8c1c-cbf333395c93',\n",
       " '71be8f37-349a-49e8-b8b5-4a0fa8ded246',\n",
       " '6b34b851-20dd-4e54-8d68-049241ba792c',\n",
       " '5083bb81-2254-4330-be3d-4364e12b2b28',\n",
       " '8d9f676d-f4f9-404b-9ea8-ceeb81edaa6e',\n",
       " '9783bf6b-09ef-4268-8af8-20445f136eb7',\n",
       " '6336be50-770e-4caa-8064-10d3ebec0df5',\n",
       " '3189b67f-b49d-428d-8bc8-0e22f38c1a40',\n",
       " '7fe8c42f-c72d-4430-8628-96284469f918',\n",
       " '6ad1d763-a3c5-42c7-8192-6d3cd007d9dd',\n",
       " '7d5917b3-102e-4e6d-b5b0-adf4c5d9b789',\n",
       " 'bfd212a5-224d-48bf-97e8-aaa9adab2f68']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama.embeddings import OllamaEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "embeddings  = OllamaEmbeddings(\n",
    "  model='mxbai-embed-large'\n",
    ")\n",
    "\n",
    "vectorstore = PineconeVectorStore(embedding=embeddings, index=index )\n",
    "\n",
    "vectorstore.add_documents(documents=splited_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(model=\"llama3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "vH2LgSnSeuL3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next.js is a full-stack React framework for building web applications. According to its documentation, it provides everything you need to build great products on the web.\n",
      "\n",
      "Some of its key features include:\n",
      "\n",
      "1. **Data Fetching**: Make your React component async and await your data. Next.js supports both server and client-side data fetching.\n",
      "2. **Server Actions**: Run server code by calling a function. This allows for easy revalidation of cached data and updating the UI in one network roundtrip.\n",
      "3. **Advanced Routing & Nested Layouts**: Create routes using the file system, including support for more advanced routing patterns and UI layouts.\n",
      "4. **CSS Support**: Style your application with ease.\n",
      "\n",
      "Additionally, Next.js offers:\n",
      "\n",
      "1. **Server Rendering**: Enable flexible rendering and caching options, including Incremental Static Regeneration (ISR) on a per-page level.\n",
      "2. **Turbopack**: An incremental bundler optimized for JavaScript and TypeScript, written in Rust, which is used to build the framework.\n",
      "\n",
      "Next.js is trusted by some of the biggest names on the web, including Audible, Sonos, Dice, Notion, Product Hunt, Nike, Washington Post, and many more. It's also built on a foundation of fast, production-grade tooling and powered by React, making it a popular choice for building high-performance ecommerce sites and other web applications.\n",
      "\n",
      "Overall, Next.js is an all-in-one starter kit that provides everything you need to build great products on the web, with a focus on performance, efficiency, and developer experience.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(model=\"llama3\")\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\")\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"Use the following context to answer the question.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "response = chain.invoke(\"tell me about Next.js\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-29 12:42:24.554 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\PC\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2026-01-29 12:42:24.554 Session state does not function when running a script without `streamlit run`\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import os\n",
    "from pinecone import Pinecone\n",
    "\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_ollama.embeddings import OllamaEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# ----------------- Pinecone Setup ----------------- #\n",
    "PINECONE_API_KEY = \"pcsk_476Mbq_K7Z3aCy8BqmFGYrsbHHwhoeRLcfz9yWg8qbpmZMFBEnCMZR6PsPqPiuzDs9neEe\"\n",
    "os.environ[\"PINECONE_API_KEY\"] = PINECONE_API_KEY\n",
    "\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "index = pc.Index(\"chatbot-index\")  # Make sure this index exists and has the correct dimension (1024)\n",
    "\n",
    "# ----------------- Streamlit UI ----------------- #\n",
    "st.set_page_config(layout=\"wide\")\n",
    "st.title(\"My Modern Local Chatbot\")\n",
    "\n",
    "st.sidebar.header(\"Settings\")\n",
    "MODEL = st.sidebar.selectbox(\n",
    "    \"Choose a Model\",\n",
    "    [\"llama3.2\", \"deepseek-r1:1.5b\"],\n",
    "    index=0\n",
    ")\n",
    "MAX_HISTORY = st.sidebar.number_input(\"Max History\", 1, 10, 2)\n",
    "\n",
    "# ----------------- Session State ----------------- #\n",
    "if \"chat_history\" not in st.session_state:\n",
    "    st.session_state.chat_history = []\n",
    "\n",
    "# ----------------- LangChain Components ----------------- #\n",
    "llm = ChatOllama(\n",
    "    model=MODEL,\n",
    "    streaming=True  # Token streaming enabled\n",
    ")\n",
    "\n",
    "embeddings = OllamaEmbeddings(model=\"mxbai-embed-large\")\n",
    "\n",
    "vectorstore = PineconeVectorStore(\n",
    "    index=index,\n",
    "    embedding=embeddings\n",
    ")\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\")\n",
    "\n",
    "# ----------------- Prompt Template ----------------- #\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"\"\"You are a helpful assistant.\n",
    "Use the context below to answer the question.\n",
    "If the answer is not in the context, say so clearly.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\"\"\"\n",
    ")\n",
    "\n",
    "# ----------------- LCEL Chain ----------------- #\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt_template\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# ----------------- Display Chat History ----------------- #\n",
    "for msg in st.session_state.chat_history:\n",
    "    with st.chat_message(msg[\"role\"]):\n",
    "        st.markdown(msg[\"content\"])\n",
    "\n",
    "# ----------------- Trim History ----------------- #\n",
    "def trim_history():\n",
    "    while len(st.session_state.chat_history) > MAX_HISTORY * 2:\n",
    "        st.session_state.chat_history.pop(0)\n",
    "\n",
    "# ----------------- Chat Input ----------------- #\n",
    "if question := st.chat_input(\"Ask something\"):\n",
    "    st.session_state.chat_history.append({\"role\": \"user\", \"content\": question})\n",
    "\n",
    "    with st.chat_message(\"user\"):\n",
    "        st.markdown(question)\n",
    "\n",
    "    trim_history()\n",
    "\n",
    "    with st.chat_message(\"assistant\"):\n",
    "        response_box = st.empty()\n",
    "        streamed_text = \"\"\n",
    "\n",
    "        # -------- Retrieve Documents (NEW retriever API) -------- #\n",
    "        docs = retriever(question)  # NEW: retriever is callable\n",
    "        context_text = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "        # -------- Prepare LCEL input -------- #\n",
    "        lcel_input = {\"context\": context_text, \"question\": question}\n",
    "\n",
    "        # -------- Stream Tokens -------- #\n",
    "        for token in chain.stream(lcel_input):\n",
    "            streamed_text += token\n",
    "            response_box.markdown(streamed_text)\n",
    "\n",
    "        # -------- Show Sources -------- #\n",
    "        if docs:\n",
    "            with st.expander(\"ðŸ“š Sources\"):\n",
    "                for i, doc in enumerate(docs, 1):\n",
    "                    source = doc.metadata.get(\"source\", \"Unknown\")\n",
    "                    st.markdown(f\"**{i}.** {source}\")\n",
    "\n",
    "        # -------- Save to Session State -------- #\n",
    "        st.session_state.chat_history.append({\"role\": \"assistant\", \"content\": streamed_text})\n",
    "\n",
    "        trim_history()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
